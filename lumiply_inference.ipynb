{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed115ed6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1765309321220,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "yWtRWFoiLvVV",
    "outputId": "902eac59-2a67-4c39-bbfd-95f7d61f91ce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/LumiNet_Files/lumiply-colab\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/LumiNet_Files/lumiply-colab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9146,
     "status": "ok",
     "timestamp": 1765309331149,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "OMYjtM_bLyVT",
    "outputId": "710aace5-c1d7-4b14-e385-68678e1ab5b2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: open-clip-torch==2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: positional-encodings in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.12.0.88)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: OmegaConf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: torchviz in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.0.3)\n",
      "Requirement already satisfied: pytorch-lightning==1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: transformers>=4.45.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
      "Requirement already satisfied: xformers==0.0.32.post2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.0.32.post2)\n",
      "Requirement already satisfied: share in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.0.4)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==2.0.1->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==2.0.1->-r requirements.txt (line 1)) (6.3.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==2.0.1->-r requirements.txt (line 1)) (2025.11.3)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open-clip-torch==2.0.1->-r requirements.txt (line 1)) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (2.0.2)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (6.0.3)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (2025.3.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (2.19.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.8.2)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (0.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from OmegaConf->-r requirements.txt (line 6)) (4.9.3)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchviz->-r requirements.txt (line 7)) (0.21)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0->-r requirements.txt (line 9)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0->-r requirements.txt (line 9)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch==2.0.1->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (5.29.5)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (0.15.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open-clip-torch==2.0.1->-r requirements.txt (line 1)) (0.2.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0->-r requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0->-r requirements.txt (line 9)) (2025.11.12)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open-clip-torch==2.0.1->-r requirements.txt (line 1)) (11.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0->-r requirements.txt (line 8)) (1.22.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
      "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# LumiNet íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -r requirements.txt\n",
    "# Flask íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install flask flask-cors requests pillow pyngrok torchvision flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "f74feb747fa8439789eb8a1b55cdd6b9",
      "e42ab383a67949a99028884b55a29253",
      "226963da0932460ea0f314fbbf810b28",
      "86041c94cb9447eba1cdb16ceffb7c46",
      "de58cdbb22994aefbadb00b2786c5062",
      "707f9b01a5e04c3ca369807411671864",
      "d96bbb330d154ba6934f9c7a7e30ed0f",
      "ebdc1dbb716a47088157d4884ff9007e",
      "0fd9ee0313ed49a29fd5e851ed283699",
      "f834a9ffafbc431e9628911ca5f508ea",
      "bf575732116c41658f8375e54a02245d",
      "f446cba415e04c4799316f2281198d61",
      "4386bf5f26424f11960141fc16cef6fa",
      "2c84ec65d4eb4494a19d08feb1c16c0b",
      "06fdaaa637584c16a8bb8d86cecf7862",
      "9966b628983445c3b689f8feb2a1487e",
      "d5fd2a6b053c48208ae2822b39c9310f",
      "a14d9043a10848fa95ebc6e5d61cc1da",
      "f683a3b966694ee5966a83c21c9f5bd6",
      "43e515ac4df848198df50d34e699ceba"
     ]
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1765309340212,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "aUxy3_XcQKsR",
    "outputId": "32761748-369e-4e2a-8738-0ea5bb005c4c"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f74feb747fa8439789eb8a1b55cdd6b9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jfMUIOSS8noQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1765309346533,
     "user_tz": -540,
     "elapsed": 205,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     }
    }
   },
   "outputs": [],
   "source": [
    "!lsof -i | grep :5000 # ì•„ë¬´ê²ƒë„ ì•ˆ ë– ì•¼í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFu9p_P18s3J"
   },
   "outputs": [],
   "source": [
    "# !kill -9 712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56066,
     "status": "ok",
     "timestamp": 1765309404175,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "pzDH8NyOKRUE",
    "outputId": "53edd04c-86c9-4594-fada-195aea571c9b",
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì‹œì‘... (ìµœì´ˆ 1íšŒ)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/lightning.py:2058: DeprecationWarning: `torch.distributed._sharded_tensor` will be deprecated, use `torch.distributed._shard.sharded_tensor` instead\n",
      "  from torch.distributed._sharded_tensor import pre_load_state_dict_hook, state_dict_hook\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ControlLDM: Running in v-prediction mode\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "DiffusionWrapper has 1042.99 M params.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.\n",
      "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.\n",
      "Loaded state_dict from [./ckpt/trained_crossattn.ckpt]\n",
      "Base Model ë¡œë“œ ì™„ë£Œ: ./ckpt/trained_crossattn.ckpt\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Successfully load new auto-encoder\n",
      "ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# [Cell 1] ëª¨ë¸/ì—”ì§„ ì´ˆê¸°í™” (ì•½ 5~10ë¶„ ì†Œìš”)\n",
    "# =========================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from cldm.model import load_state_dict\n",
    "from cldm.ddim_hacked import DDIMSampler\n",
    "import einops\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì • (Colab ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "# BASE_MODEL_PATH = \"./crossattn_checkpoints/best_crossattn_offwhite.ckpt\"\n",
    "BASE_MODEL_PATH = \"./ckpt/trained_crossattn.ckpt\"\n",
    "CONFIG_PATH = \"./models/cldm_v21_LumiNet.yaml\"\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ (ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ê³„ì† ìœ ì§€í•˜ê¸° ìœ„í•¨)\n",
    "global_model = None\n",
    "global_sampler = None\n",
    "current_adapter_color = None\n",
    "\n",
    "def initialize_engine():\n",
    "    \"\"\"ë² ì´ìŠ¤ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    global global_model, global_sampler\n",
    "\n",
    "    if global_model is not None:\n",
    "        print(\"ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(\"ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì‹œì‘... (ìµœì´ˆ 1íšŒ)\")\n",
    "    config = OmegaConf.load(CONFIG_PATH)\n",
    "    model = instantiate_from_config(config.model).cpu()\n",
    "    model.add_new_layers()\n",
    "\n",
    "    if os.path.exists(BASE_MODEL_PATH):\n",
    "        model.load_state_dict(load_state_dict(BASE_MODEL_PATH, location='cpu'), strict=False)\n",
    "        print(f\"Base Model ë¡œë“œ ì™„ë£Œ: {BASE_MODEL_PATH}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Base Model ì—†ìŒ: {BASE_MODEL_PATH}\")\n",
    "\n",
    "    new_decoder = True #\n",
    "    if new_decoder: #\n",
    "        ae_checkpoint = \"./ckpt/new_decoder.ckpt\" #\n",
    "        model.change_first_stage(ae_checkpoint) #\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    global_model = model\n",
    "    global_sampler = DDIMSampler(model)\n",
    "    print(\"ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "\n",
    "def switch_adapter(target_color):\n",
    "    \"\"\"ìš”ì²­ëœ ìƒ‰ìƒìœ¼ë¡œ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ë§Œ êµì²´í•©ë‹ˆë‹¤.\"\"\"\n",
    "    global global_model, current_adapter_color\n",
    "\n",
    "    if current_adapter_color == target_color:\n",
    "        print(f\"ì´ë¯¸ {target_color} ì–´ëŒ‘í„°ê°€ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    weights_path = f\"./adaptors/adaptor_{target_color}.pth\"\n",
    "\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"(White ëª¨ë“œë¡œ ì§„í–‰)\")\n",
    "        current_adapter_color = \"none\"\n",
    "        return\n",
    "\n",
    "    print(f\"ì–´ëŒ‘í„° êµì²´ ì¤‘... ({current_adapter_color} -> {target_color})\")\n",
    "    checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "\n",
    "    # Hot-Swapping (ëª¨ë¸ì„ ë„ì§€ ì•Šê³  ê°€ì¤‘ì¹˜ë§Œ ë®ì–´ì“°ê¸°)\n",
    "    if 'light_encoder' in checkpoint:\n",
    "        global_model.control_model.prior_extracter.model_latents.light_encoder.load_state_dict(checkpoint['light_encoder'])\n",
    "    if 'light_decoder' in checkpoint:\n",
    "        global_model.control_model.prior_extracter.light_decoder.load_state_dict(checkpoint['light_decoder'])\n",
    "\n",
    "    # ==================================================\n",
    "    # ì •ë°€ ê²€ì¦ (Verification)\n",
    "    print(\"\\nğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\")\n",
    "    is_valid = True\n",
    "\n",
    "    # Encoder ê²€ì¦\n",
    "    if 'light_encoder' in checkpoint:\n",
    "        key = list(checkpoint['light_encoder'].keys())[0]\n",
    "\n",
    "        # [ìˆ˜ì •] ë¹„êµ ì „ì— ë‘˜ ë‹¤ CPUë¡œ ì´ë™\n",
    "        file_val = checkpoint['light_encoder'][key].cpu()\n",
    "        model_val = global_model.control_model.prior_extracter.model_latents.light_encoder.state_dict()[key].cpu()\n",
    "\n",
    "        if torch.allclose(file_val, model_val, atol=1e-6):\n",
    "            print(f\"Encoder ê²€ì¦ í†µê³¼! (Key: {key})\")\n",
    "        else:\n",
    "            print(f\"Encoder ê²€ì¦ ì‹¤íŒ¨! ê°’ì´ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "            is_valid = False\n",
    "\n",
    "    # Adaptor ê²€ì¦\n",
    "    if 'light_decoder' in checkpoint:\n",
    "        key = list(checkpoint['light_decoder'].keys())[0]\n",
    "\n",
    "        # [ìˆ˜ì •] ë¹„êµ ì „ì— ë‘˜ ë‹¤ CPUë¡œ ì´ë™\n",
    "        file_val = checkpoint['light_decoder'][key].cpu()\n",
    "        model_val = global_model.control_model.prior_extracter.light_decoder.state_dict()[key].cpu()\n",
    "\n",
    "        if torch.allclose(file_val, model_val, atol=1e-6):\n",
    "            print(f\"Adaptor ê²€ì¦ í†µê³¼! (Key: {key})\")\n",
    "        else:\n",
    "            print(f\"Adaptor ê²€ì¦ ì‹¤íŒ¨! ê°’ì´ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "            is_valid = False\n",
    "\n",
    "    if not is_valid:\n",
    "        print(\"ê²½ê³ : ê°€ì¤‘ì¹˜ê°€ ì œëŒ€ë¡œ ì ìš©ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\")\n",
    "    # ==================================================\n",
    "\n",
    "    current_adapter_color = target_color\n",
    "    print(f\"{target_color} ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\")\n",
    "\n",
    "def run_inference_single_image(off_path, color, guidance_scale=9.0, ddim_steps=50):\n",
    "    \"\"\"\n",
    "    off_path: í•©ì„±ëœ 'off' ì´ë¯¸ì§€ ê²½ë¡œ (ì›ë³¸ í•´ìƒë„)\n",
    "    color: 'red', 'orange', 'yellow', 'green', 'blue', 'purple' ë“±\n",
    "    ë°˜í™˜: ì €ì¥ëœ ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    switch_adapter(color)\n",
    "    new_decoder = True #\n",
    "\n",
    "    print(f\"\\nSingle Image ì²˜ë¦¬ ì‹œì‘: {off_path} (Color: {color})\")\n",
    "\n",
    "    img_off = Image.open(off_path).convert(\"RGB\")\n",
    "    orig_w, orig_h = img_off.size\n",
    "    img_off_resized = img_off.resize((512, 512), Image.BICUBIC)\n",
    "    img_ref_resized = Image.new(\"RGB\", (512, 512), (255, 255, 255))\n",
    "\n",
    "    t_off = torch.from_numpy(np.array(img_off_resized).astype(np.float32) / 255.0).permute(2,0,1).unsqueeze(0).cuda()\n",
    "    t_ref = torch.from_numpy(np.array(img_ref_resized).astype(np.float32) / 255.0).permute(2,0,1).unsqueeze(0).cuda()\n",
    "\n",
    "    hint = torch.cat((t_off, t_ref), dim=1)\n",
    "\n",
    "    input_image_full = cv2.imread(off_path)[..., ::-1] / 255.0 #\n",
    "    inp = cv2.resize(input_image_full, (512, 512)) #\n",
    "    input_img = torch.from_numpy(inp.copy()).float().cuda() #\n",
    "    input_img = input_img.unsqueeze(0) #\n",
    "    input_img = einops.rearrange(input_img, 'b h w c -> b c h w').clone() #\n",
    "\n",
    "    # ì¶”ë¡ \n",
    "    with torch.no_grad():\n",
    "        c_cat = hint\n",
    "        c = global_model.get_unconditional_conditioning(c_cat.shape[0])\n",
    "        cond = {\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n",
    "        shape = (4, 512 // 8, 512 // 8)\n",
    "\n",
    "        samples, _ = global_sampler.sample(\n",
    "            ddim_steps, 1, shape, cond, verbose=False,\n",
    "            unconditional_guidance_scale=guidance_scale\n",
    "        )\n",
    "\n",
    "        # x_sample = global_model.decode_first_stage(samples)\n",
    "        # x_sample = torch.clamp((x_sample + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "        if new_decoder: #\n",
    "            ae_hs = global_model.encode_first_stage(input_img * 2 - 1)[1] #\n",
    "            x_sample = global_model.decode_new_first_stage(samples, ae_hs) #\n",
    "        else: #\n",
    "            x_sample = global_model.decode_first_stage(samples) #\n",
    "        x_sample = torch.clamp((x_sample + 1.0) / 2.0, min=0.0, max=1.0) #\n",
    "\n",
    "        result_numpy = x_sample.cpu().permute(0, 2, 3, 1).numpy()[0] * 255\n",
    "        result_numpy = result_numpy.astype(np.uint8)\n",
    "        result_final = cv2.resize(result_numpy, (orig_w, orig_h), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        # ì €ì¥ ê²½ë¡œëŠ” off_path ê¸°ì¤€ìœ¼ë¡œ output_{color}.jpg\n",
    "        root, fname = os.path.split(off_path)\n",
    "        save_path = os.path.join(root, f\"output_{color}.jpg\")\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(result_final, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "# ê¸°ì¡´ run_process(inference_root, color)ëŠ” ì—¬ëŸ¬ íŒŒì¼ batch ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ê³ ,\n",
    "# ì˜¨ë¼ì¸ ìš”ì²­ìš©ìœ¼ë¡œëŠ” run_inference_single_image(...)ë¥¼ í•µì‹¬ìœ¼ë¡œ ì‚¬ìš©.\n",
    "\n",
    "initialize_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AW0ckY3iLt_C",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1765309433324,
     "user_tz": -540,
     "elapsed": 49,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     }
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# [Cell 2] Flask + ngrok ì„œë²„\n",
    "# =========================\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "INFERENCE_ROOT = \"./images/inference\"\n",
    "os.makedirs(INFERENCE_ROOT, exist_ok=True)\n",
    "\n",
    "PUBLIC_URL = None  # [Cell 3] ì—ì„œ ngrok.connect í›„ ì±„ì›€\n",
    "\n",
    "@app.before_request\n",
    "def handle_ngrok_warning():\n",
    "    \"\"\"ngrok ë¸Œë¼ìš°ì € ê²½ê³  í˜ì´ì§€ ìš°íšŒ\"\"\"\n",
    "    if request.headers.get(\"ngrok-skip-browser-warning\"):\n",
    "        pass\n",
    "\n",
    "@app.before_request\n",
    "def log_request_info():\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ìš”ì²­ ìˆ˜ì‹ : {request.method} {request.path}\")\n",
    "    print(f\"Headers: {dict(request.headers)}\")\n",
    "    if request.method == \"POST\":\n",
    "        print(f\"Form data keys: {list(request.form.keys())}\")\n",
    "        print(f\"Files keys: {list(request.files.keys())}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "@app.route(\"/health\", methods=[\"GET\"])\n",
    "def health_check():\n",
    "    print(\"Health check ìš”ì²­ ìˆ˜ì‹ \")\n",
    "    return jsonify(\n",
    "        {\n",
    "            \"status\": \"healthy\",\n",
    "            \"message\": \"Colab ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.\",\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "    ), 200\n",
    "\n",
    "@app.route(\"/process\", methods=[\"POST\"])\n",
    "def process_image():\n",
    "    \"\"\"\n",
    "    FastAPIì—ì„œ ì „ì†¡ëœ í•©ì„± ì´ë¯¸ì§€ë¥¼ ë°›ì•„,\n",
    "    /images/inference/{job_id}/off.png ë¡œ ì €ì¥í•œ ë’¤,\n",
    "    ìš”ì²­ëœ ë‹¨ì¼ ìƒ‰ìƒ(color)ì— ëŒ€í•´ì„œë§Œ output_{color}.jpg ë¥¼ ìƒì„±í•˜ê³ ,\n",
    "    í•´ë‹¹ ìƒ‰ìƒ ê²°ê³¼ + ì…ë ¥(off) ì´ë¯¸ì§€ URL ì„ FastAPI/í”„ë¡ íŠ¸ì— ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if \"image\" not in request.files:\n",
    "            print(\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return jsonify({\"error\": \"ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\"}), 400\n",
    "\n",
    "        file = request.files[\"image\"]\n",
    "        job_id = request.form.get(\"job_id\")\n",
    "        callback_url = request.form.get(\"callback_url\")\n",
    "        color_param = request.form.get(\"color\")  # â˜… ì¶”ê°€: ë‹¨ì¼ ìƒ‰ìƒ ì§€ì •\n",
    "\n",
    "        print(f\"ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\")\n",
    "        print(f\"   - job_id: {job_id}\")\n",
    "        print(f\"   - callback_url: {callback_url}\")\n",
    "        print(f\"   - color: {color_param}\")\n",
    "        print(f\"   - íŒŒì¼ëª…: {file.filename}\")\n",
    "        print(f\"   - íŒŒì¼ íƒ€ì…: {file.content_type}\")\n",
    "\n",
    "        if not job_id:\n",
    "            print(\"job_idê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return jsonify({\"error\": \"job_idê°€ ì—†ìŠµë‹ˆë‹¤.\"}), 400\n",
    "\n",
    "        # ì§€ì› ìƒ‰ìƒ ê²€ì¦ (ë‹¨ì¼ ìƒ‰ìƒë§Œ í—ˆìš©)\n",
    "        base_colors = [\"white\", \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\"]\n",
    "        if not color_param:\n",
    "            return jsonify({\"error\": \"color íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.\"}), 400\n",
    "        if color_param not in base_colors:\n",
    "            return jsonify({\"error\": f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìƒ‰ìƒì…ë‹ˆë‹¤: {color_param}\"}), 400\n",
    "\n",
    "        color_key = color_param\n",
    "\n",
    "        if not callback_url:\n",
    "            print(\"callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        print(f\"[{job_id}] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\")\n",
    "\n",
    "        # 1) job ì „ìš© ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        job_dir = os.path.join(INFERENCE_ROOT, job_id)\n",
    "        os.makedirs(job_dir, exist_ok=True)\n",
    "\n",
    "        # 2) ì…ë ¥ ì´ë¯¸ì§€ë¥¼ off.png ë¡œ ì €ì¥\n",
    "        off_path = os.path.join(job_dir, \"off.png\")\n",
    "        image_bytes = file.read()\n",
    "        with open(off_path, \"wb\") as f:\n",
    "            f.write(image_bytes)\n",
    "\n",
    "        print(f\"[{job_id}] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {off_path}\")\n",
    "        print(f\"[{job_id}] ì´ë¯¸ì§€ í¬ê¸°: {len(image_bytes)} bytes\")\n",
    "\n",
    "        from pathlib import Path\n",
    "\n",
    "        images = {}\n",
    "        # for ck in color_key:\n",
    "        print(f\"[{job_id}] === {color_key} ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "        output_path = run_inference_single_image(off_path=off_path, color=color_key)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            rel_path = f\"/static/inference/{job_id}/{Path(output_path).name}\"\n",
    "            images[color_key] = f\"{PUBLIC_URL}{rel_path}\"\n",
    "            print(f\"[{job_id}] {color_key} ê²°ê³¼ URL: {images[color_key]}\")\n",
    "        else:\n",
    "            print(f\"[{job_id}] {color_key} ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {output_path}\")\n",
    "\n",
    "        # ì¸í’‹(off) ì´ë¯¸ì§€ URL\n",
    "        input_rel = f\"/static/inference/{job_id}/off.png\"\n",
    "        input_image_url = f\"{PUBLIC_URL}{input_rel}\"\n",
    "\n",
    "        response_data = {\n",
    "            \"job_id\": job_id,\n",
    "            \"status\": \"completed\",\n",
    "            \"result\": {\n",
    "                \"images\": images,\n",
    "                \"input_image_url\": input_image_url,\n",
    "            },\n",
    "            \"message\": \"ìƒ‰ìƒ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ\",\n",
    "        }\n",
    "\n",
    "        # ì½œë°±\n",
    "        if callback_url:\n",
    "            try:\n",
    "                print(f\"[{job_id}] FastAPIë¡œ ê²°ê³¼ ì „ì†¡ ì¤‘...\")\n",
    "                callback_response = requests.post(\n",
    "                    callback_url,\n",
    "                    json=response_data,\n",
    "                    timeout=60,\n",
    "                    headers={\"ngrok-skip-browser-warning\": \"true\"},\n",
    "                )\n",
    "                print(f\"[{job_id}] ì½œë°± ì‘ë‹µ ìƒíƒœ: {callback_response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{job_id}] ì½œë°± ì „ì†¡ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "        print(f\"[{job_id}] ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "        return jsonify(response_data), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"ì²˜ë¦¬ ì˜¤ë¥˜: {error_msg}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({\"success\": False, \"error\": error_msg}), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3033,
     "status": "ok",
     "timestamp": 1765309437339,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "CNa9tq4IMuF5",
    "outputId": "32ce5751-65a2-4706-9f16-26e9e08e1fc7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Flask ì„œë²„ ì‹œì‘... (0.0.0.0:5000)\n",
      "Flask ì„œë²„ ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘\n",
      "==================================================\n",
      "âœ… Colab ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸŒ Public URL: https://undented-preinflectional-madeline.ngrok-free.dev\n",
      "ğŸ“ FastAPIì˜ COLAB_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ì— ë‹¤ìŒ URLì„ ì„¤ì •í•˜ì„¸ìš”:\n",
      "   https://undented-preinflectional-madeline.ngrok-free.dev/process\n",
      "==================================================\n",
      "\n",
      "ğŸ’¡ ë³µì‚¬í•  URL:\n",
      "   https://undented-preinflectional-madeline.ngrok-free.dev/process\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# [Cell 3] ngrok + Flask ì„œë²„ (ë°±ê·¸ë¼ìš´ë“œ) ì„¤ì •\n",
    "# =========================\n",
    "\n",
    "from pyngrok import ngrok\n",
    "from werkzeug.middleware.shared_data import SharedDataMiddleware\n",
    "from werkzeug.serving import make_server\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# 1) ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (Flask appì€ ì´ë¯¸ Cell 2ì—ì„œ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n",
    "app.wsgi_app = SharedDataMiddleware(app.wsgi_app, {\n",
    "    \"/static/inference\": INFERENCE_ROOT,\n",
    "})\n",
    "\n",
    "# 2) Flask ì„œë²„ë¥¼ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ëŒë¦¬ê¸° ìœ„í•œ í´ë˜ìŠ¤\n",
    "class FlaskServerThread(threading.Thread):\n",
    "    def __init__(self, app, host=\"0.0.0.0\", port=5000):\n",
    "        super().__init__()\n",
    "        self.app = app\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.server = None\n",
    "        self.ctx = None\n",
    "        self.daemon = True  # ë…¸íŠ¸ë¶ ì¢…ë£Œ ì‹œ ê°™ì´ ì£½ë„ë¡\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Flask ì„œë²„ ì‹œì‘... ({self.host}:{self.port})\")\n",
    "        # WSGI ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì¡ì•„ë‘”ë‹¤\n",
    "        self.server = make_server(self.host, self.port, self.app)\n",
    "        self.ctx = self.app.app_context()\n",
    "        self.ctx.push()\n",
    "        try:\n",
    "            self.server.serve_forever()\n",
    "        finally:\n",
    "            self.server.server_close()\n",
    "            self.ctx.pop()\n",
    "            print(\"Flask ì„œë²„ ì¢…ë£Œ ì™„ë£Œ\")\n",
    "\n",
    "    def shutdown(self):\n",
    "        if self.server:\n",
    "            print(\"Flask ì„œë²„ shutdown ìš”ì²­\")\n",
    "            self.server.shutdown()  # serve_forever ë£¨í”„ ê¹¨ê¸°\n",
    "\n",
    "# 3) ì´ë¯¸ ì—´ë ¤ ìˆëŠ” ngrok í„°ë„ì´ ìˆìœ¼ë©´ ì •ë¦¬\n",
    "if \"NGROK_TUNNEL\" in globals() and NGROK_TUNNEL is not None:\n",
    "    try:\n",
    "        print(\"ê¸°ì¡´ ngrok í„°ë„ ë‹«ëŠ” ì¤‘:\", NGROK_TUNNEL.public_url)\n",
    "        NGROK_TUNNEL.close()\n",
    "    except Exception as e:\n",
    "        print(\"ê¸°ì¡´ í„°ë„ close ì¤‘ ì˜¤ë¥˜:\", e)\n",
    "    NGROK_TUNNEL = None\n",
    "\n",
    "# 4) Flask ì„œë²„ ìŠ¤ë ˆë“œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)\n",
    "flask_server = FlaskServerThread(app, host=\"0.0.0.0\", port=5000)\n",
    "flask_server.start()\n",
    "\n",
    "# ì„œë²„ê°€ ëœ° ì‹œê°„ ì•½ê°„ ëŒ€ê¸°\n",
    "time.sleep(2)\n",
    "print(\"Flask ì„œë²„ ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "# 5) ngrok ì„¤ì •\n",
    "NGROK_TOKEN = \"NGROK_TOKEN_ì…ë ¥\"\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "ngrok.kill()  # í˜¹ì‹œ ë‚¨ì•„ ìˆì„ ìˆ˜ ìˆëŠ” ngrok í”„ë¡œì„¸ìŠ¤ ì •ë¦¬\n",
    "\n",
    "# ìƒˆ í„°ë„ ìƒì„± (Flaskê°€ 5000 í¬íŠ¸ì—ì„œ ì´ë¯¸ LISTEN ì¤‘ì´ì–´ì•¼ í•¨)\n",
    "NGROK_TUNNEL = ngrok.connect(5000)\n",
    "\n",
    "public_url = getattr(NGROK_TUNNEL, \"public_url\", str(NGROK_TUNNEL))\n",
    "\n",
    "if public_url.startswith(\"http://\"):\n",
    "    public_url = public_url.replace(\"http://\", \"https://\")\n",
    "elif not public_url.startswith(\"https://\"):\n",
    "    public_url = f\"https://{public_url}\"\n",
    "\n",
    "PUBLIC_URL = public_url\n",
    "process_url = f\"{public_url}/process\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Colab ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸŒ Public URL: {public_url}\")\n",
    "print(\"ğŸ“ FastAPIì˜ COLAB_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ì— ë‹¤ìŒ URLì„ ì„¤ì •í•˜ì„¸ìš”:\")\n",
    "print(f\"   {process_url}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nğŸ’¡ ë³µì‚¬í•  URL:\")\n",
    "print(f\"   {process_url}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# # Flask ì„œë²„ ì¢…ë£Œ\n",
    "\n",
    "# flask_server.shutdown()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Qi_K23yLNTI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1765310614293,
     "user_tz": -540,
     "elapsed": 240,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     }
    },
    "outputId": "11397fb2-212d-43cf-dab7-aed82bb850c1"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Flask ì„œë²„ shutdown ìš”ì²­\n",
      "Flask ì„œë²„ ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## í…ŒìŠ¤íŠ¸ ì½”ë“œ"
   ],
   "metadata": {
    "id": "qGurvgoHJ_a6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fa94SmVTEUve",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1765207885310,
     "user_tz": -540,
     "elapsed": 107,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     }
    },
    "outputId": "1853e8f7-f908-4c9d-f9b2-a179faeba1ed"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/LumiNet_Files/LumiNet-lee\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141547,
     "status": "ok",
     "timestamp": 1765208027785,
     "user": {
      "displayName": "ì§€ëŠ¥ì •ë³´ SWì•„ì¹´ë°ë¯¸5ì¡°",
      "userId": "16997830524223997531"
     },
     "user_tz": -540
    },
    "id": "PDPYyaGQ7XaV",
    "outputId": "d252463c-4f64-492f-bfd3-a168f1edd489"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "Sending request for color: white\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717510', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=ca8e0f2a1c067cae162ce6be65f4e061', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: white\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === white ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "(White ëª¨ë“œë¡œ ì§„í–‰)\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: white)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.65it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:31:40] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_white.jpg\n",
      "[debug-job] white ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_white.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"white\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_white.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: red\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717508', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=26c2959e32540c703eadf1d8e73488d1', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: red\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === red ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (none -> red)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "red ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: red)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  8.96it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:31:59] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_red.jpg\n",
      "[debug-job] red ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_red.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"red\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_red.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: orange\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717511', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=834074b8b21b54950d4e6d92a2137a9c', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: orange\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === orange ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (red -> orange)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "orange ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: orange)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  8.96it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:32:24] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_orange.jpg\n",
      "[debug-job] orange ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_orange.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"orange\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_orange.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: yellow\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717511', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=c54fb788c94dfea7323b2b56fb01bf47', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: yellow\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === yellow ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (orange -> yellow)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "yellow ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: yellow)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  8.94it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:32:38] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_yellow.jpg\n",
      "[debug-job] yellow ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_yellow.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"yellow\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_yellow.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: green\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717510', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=4187ad76fa0cb76ce99e5ded92a1394b', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: green\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === green ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (yellow -> green)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "green ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: green)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  9.00it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:32:59] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_green.jpg\n",
      "[debug-job] green ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_green.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"green\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_green.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: blue\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717509', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=17fbda1a60db98ba7f35a9701158e34f', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: blue\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === blue ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (green -> blue)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "blue ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: blue)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  8.93it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:33:23] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_blue.jpg\n",
      "[debug-job] blue ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_blue.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"blue\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_blue.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n",
      "==================================================\n",
      "Sending request for color: purple\n",
      "==================================================\n",
      "ìš”ì²­ ìˆ˜ì‹ : POST /process\n",
      "Headers: {'Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'User-Agent': 'python-requests/2.32.4', 'Content-Length': '717511', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Content-Type': 'multipart/form-data; boundary=70370bd63a99bc476bd25a34e94218a8', 'Ngrok-Skip-Browser-Warning': 'true', 'X-Forwarded-For': '34.126.159.241', 'X-Forwarded-Host': 'undented-preinflectional-madeline.ngrok-free.dev', 'X-Forwarded-Proto': 'https'}\n",
      "Form data keys: ['job_id', 'callback_url', 'color']\n",
      "Files keys: ['image']\n",
      "==================================================\n",
      "==================================================\n",
      "Process ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨!\n",
      "==================================================\n",
      "ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°:\n",
      "   - job_id: debug-job\n",
      "   - callback_url: \n",
      "   - color: purple\n",
      "   - íŒŒì¼ëª…: 23_off.jpeg\n",
      "   - íŒŒì¼ íƒ€ì…: None\n",
      "callback_urlì´ ì—†ìŠµë‹ˆë‹¤. ì½œë°±ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "[debug-job] ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
      "[debug-job] ì…ë ¥ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ./images/inference/debug-job/off.png\n",
      "[debug-job] ì´ë¯¸ì§€ í¬ê¸°: 717082 bytes\n",
      "[debug-job] === purple ìƒ‰ìƒ ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì–´ëŒ‘í„° êµì²´ ì¤‘... (blue -> purple)\n",
      "\n",
      "ğŸ” ê°€ì¤‘ì¹˜ ì ìš© ìƒíƒœ ê²€ì¦ ì¤‘...\n",
      "Encoder ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "Adaptor ê²€ì¦ í†µê³¼! (Key: 0.weight)\n",
      "ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (Color Mode ON)\n",
      "purple ì–´ëŒ‘í„° ì¥ì°© ì™„ë£Œ\n",
      "\n",
      "Single Image ì²˜ë¦¬ ì‹œì‘: ./images/inference/debug-job/off.png (Color: purple)\n",
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DDIM Sampler: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  8.86it/s]\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Dec/2025 15:33:47] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved: ./images/inference/debug-job/output_purple.jpg\n",
      "[debug-job] purple ê²°ê³¼ URL: https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_purple.jpg\n",
      "[debug-job] ì²˜ë¦¬ ì™„ë£Œ\n",
      "Status: 200\n",
      "Response: {\"job_id\":\"debug-job\",\"message\":\"\\uc0c9\\uc0c1 \\uc774\\ubbf8\\uc9c0 \\uc0dd\\uc131 \\uc644\\ub8cc\",\"result\":{\"images\":{\"purple\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/output_purple.jpg\"},\"input_image_url\":\"https://undented-preinflectional-madeline.ngrok-free.dev/static/inference/debug-job/off.png\"},\"status\":\"completed\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from PIL import Image\n",
    "# import io\n",
    "\n",
    "# colors = [\"white\", \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\"]\n",
    "# job_id = \"debug-job\"\n",
    "\n",
    "# for color in colors:\n",
    "#     print(\"=\" * 50)\n",
    "#     print(f\"Sending request for color: {color}\")\n",
    "\n",
    "#     with open(\"./23_off.jpeg\", \"rb\") as f:\n",
    "#         resp = requests.post(\n",
    "#             f\"{PUBLIC_URL}/process\",\n",
    "#             # files={\"image\": (\"off.png\", f, \"image/png\")},\n",
    "#             files={\"image\": f},\n",
    "#             data={\"job_id\": job_id, \"callback_url\": \"\", \"color\": color},\n",
    "#             headers={\"ngrok-skip-browser-warning\": \"true\"},\n",
    "#             timeout=300,\n",
    "#         )\n",
    "\n",
    "#     print(\"Status:\", resp.status_code)\n",
    "#     print(\"Response:\", resp.text[:400])  # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ì•ë¶€ë¶„ë§Œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "FF_H6JlANLPd"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "mount_file_id": "1mPVGzn39ItpG22nuyN3rF9yd2rB_jh5K",
   "authorship_tag": "ABX9TyP89yVqUVuHFLxAYndVOg+l"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}